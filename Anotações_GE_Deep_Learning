{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbrTWM7M3hsU1aKSLELXzJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hevertonvalerio/estudos/blob/main/Anota%C3%A7%C3%B5es_GE_Deep_Learning\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sepera√ß√£o dos grupos"
      ],
      "metadata": {
        "id": "nNfFtAZHtTeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Participa√ß√£o ativa - Pesquisa com materiais para pr√≥xima sess√£o.\n",
        "\n",
        "Roteiro para o econtro. Propor a condu√ß√£o de cada encontro.\n",
        "\n",
        "Exemplos de c√≥digos\n",
        "\n",
        "Alguns alunos prop√µe e os outros fazem pergunta."
      ],
      "metadata": {
        "id": "Id_975m_tfH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grupo de Introdu√ß√£o √† IA"
      ],
      "metadata": {
        "id": "THMF_Z2HwkiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. referencias de trabalho e contexto, ferram.\n",
        "\n",
        "2. eda - Como eles s√£o limpos para uma analise adequada?\n",
        "\n",
        "3. Matematica\n",
        "\n",
        "4. Se funciona ou n√£o\n",
        "\n",
        "5. Algoritimo mais simples\n",
        "\n",
        "6.\n"
      ],
      "metadata": {
        "id": "mhHBK7NbuHWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Curso AWS - Machine Learning - ML foundation**\n",
        "\n",
        "Ainda n√£o est√° dispon√≠vel - Prof Gustavo Scalabrini"
      ],
      "metadata": {
        "id": "-EKVY3uPwav4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cronograma grupo de Estudos Depp Learning"
      ],
      "metadata": {
        "id": "VCktQ1vfzf6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biblioteca > Livros eletronicos > \"Minha Biblioteca - biblioteca digital\""
      ],
      "metadata": {
        "id": "jf6evVFhzjLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apresenta√ß√£o Segunda Semana (17/09)\n",
        "\n"
      ],
      "metadata": {
        "id": "Cxg37dh1__i2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## - Estrutura de um neur√¥nio artificial\n"
      ],
      "metadata": {
        "id": "YUqzwlkOOxRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos nos aprofundar na estrutura de um neur√¥nio artificial, que √© a base das Redes Neurais Artificiais. Este conceito √© fundamental para entender como as redes neurais processam informa√ß√µes e realizam tarefas como classifica√ß√£o, regress√£o, e reconhecimento de padr√µes.\n",
        "\n",
        "1. Introdu√ß√£o ao Neur√¥nio Artificial\n",
        "Um neur√¥nio artificial √© uma abstra√ß√£o matem√°tica inspirada no neur√¥nio biol√≥gico, mas adaptada para processamento computacional. Ele √© a menor unidade de uma rede neural e tem a capacidade de aprender padr√µes a partir de dados, ajustando seus par√¢metros internos (pesos e bias) durante o treinamento.\n",
        "\n",
        "2. Componentes de um Neur√¥nio Artificial\n",
        "2.1. Entradas (Inputs)\n",
        "As entradas para um neur√¥nio artificial s√£o valores num√©ricos que representam caracter√≠sticas ou atributos dos dados. Por exemplo, em um problema de reconhecimento de d√≠gitos manuscritos, cada pixel de uma imagem pode ser uma entrada. Essas entradas s√£o representadas como um vetor\n",
        "ùë•\n",
        "=\n",
        "[\n",
        "ùë•\n",
        "1\n",
        ",\n",
        "ùë•\n",
        "2\n",
        ",\n",
        "‚Ä¶\n",
        ",\n",
        "ùë•\n",
        "ùëõ\n",
        "]\n",
        "x=[x\n",
        "1\n",
        "‚Äã\n",
        " ,x\n",
        "2\n",
        "‚Äã\n",
        " ,‚Ä¶,x\n",
        "n\n",
        "‚Äã\n",
        " ], onde cada\n",
        "ùë•\n",
        "ùëñ\n",
        "x\n",
        "i\n",
        "‚Äã\n",
        "  √© uma caracter√≠stica espec√≠fica.\n",
        "\n",
        "2.2. Pesos (Weights)\n",
        "Cada entrada\n",
        "ùë•\n",
        "ùëñ\n",
        "x\n",
        "i\n",
        "‚Äã\n",
        "  √© associada a um peso\n",
        "ùë§\n",
        "ùëñ\n",
        "w\n",
        "i\n",
        "‚Äã\n",
        " , que indica a import√¢ncia relativa daquela entrada no processo de decis√£o do neur√¥nio. Os pesos s√£o par√¢metros aprendidos durante o treinamento e s√£o ajustados para minimizar o erro da rede. A ideia √© que entradas mais relevantes para a tarefa tenham pesos maiores, enquanto entradas menos relevantes tenham pesos menores.\n",
        "\n",
        "Matematicamente, os pesos podem ser representados como um vetor\n",
        "ùë§\n",
        "=\n",
        "[\n",
        "ùë§\n",
        "1\n",
        ",\n",
        "ùë§\n",
        "2\n",
        ",\n",
        "‚Ä¶\n",
        ",\n",
        "ùë§\n",
        "ùëõ\n",
        "]\n",
        "w=[w\n",
        "1\n",
        "‚Äã\n",
        " ,w\n",
        "2\n",
        "‚Äã\n",
        " ,‚Ä¶,w\n",
        "n\n",
        "‚Äã\n",
        " ].\n",
        "\n",
        "2.3. Soma Ponderada (Weighted Sum)\n",
        "O neur√¥nio calcula a soma ponderada das entradas, que √© essencialmente uma combina√ß√£o linear das entradas e seus pesos. Essa opera√ß√£o √© crucial porque combina as informa√ß√µes das entradas em um √∫nico valor, que ser√° processado pela fun√ß√£o de ativa√ß√£o.\n",
        "\n",
        "A soma ponderada √© dada por:\n",
        "\n",
        "ùëß\n",
        "=\n",
        "‚àë\n",
        "ùëñ\n",
        "=\n",
        "1\n",
        "ùëõ\n",
        "ùë§\n",
        "ùëñ\n",
        "‚ãÖ\n",
        "ùë•\n",
        "ùëñ\n",
        "+\n",
        "ùëè\n",
        "z=\n",
        "i=1\n",
        "‚àë\n",
        "n\n",
        "‚Äã\n",
        " w\n",
        "i\n",
        "‚Äã\n",
        " ‚ãÖx\n",
        "i\n",
        "‚Äã\n",
        " +b\n",
        "Aqui,\n",
        "ùëè\n",
        "b √© o bias (vi√©s), um termo adicional que permite ao neur√¥nio ajustar a soma ponderada de maneira a n√£o depender exclusivamente das entradas. O bias ajuda o modelo a se deslocar pela fun√ß√£o de ativa√ß√£o, permitindo que a rede modele padr√µes mais complexos.\n",
        "\n",
        "2.4. Fun√ß√£o de Ativa√ß√£o\n",
        "Depois de calcular a soma ponderada, o neur√¥nio passa esse valor atrav√©s de uma fun√ß√£o de ativa√ß√£o. A fun√ß√£o de"
      ],
      "metadata": {
        "id": "eL06cjr0NeKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos aprofundar nossa compreens√£o sobre a **estrutura de um neur√¥nio artificial**, que √© a unidade fundamental de uma rede neural artificial.\n",
        "\n",
        "### 1.1. Neur√¥nio Artificial: Vis√£o Geral\n",
        "\n",
        "Um neur√¥nio artificial √© modelado para simular o comportamento de um neur√¥nio biol√≥gico. Ele recebe m√∫ltiplos sinais de entrada, processa esses sinais e gera uma sa√≠da. Esta sa√≠da pode servir como entrada para outros neur√¥nios na rede, formando um sistema interconectado.\n",
        "\n",
        "### 1.2. Componentes do Neur√¥nio Artificial\n",
        "\n",
        "Cada neur√¥nio artificial √© composto por tr√™s elementos principais:\n",
        "\n",
        "- **Entradas (\\(x_1, x_2, \\dots, x_n\\)):**\n",
        "  - Essas s√£o as caracter√≠sticas ou dados que o neur√¥nio processa. Cada entrada \\(x_i\\) representa uma caracter√≠stica do dado de entrada.\n",
        "  - Essas entradas s√£o frequentemente valores num√©ricos, como pixels de uma imagem, medi√ß√µes de sensores, ou caracter√≠sticas extra√≠das de textos.\n",
        "\n",
        "- **Pesos (\\(w_1, w_2, \\dots, w_n\\)):**\n",
        "  - Cada entrada √© associada a um peso \\(w_i\\), que determina a import√¢ncia relativa dessa entrada no c√°lculo final.\n",
        "  - Pesos s√£o par√¢metros aprend√≠veis da rede, ajustados durante o processo de treinamento. Inicialmente, eles podem ser atribu√≠dos aleatoriamente ou com base em algum crit√©rio espec√≠fico.\n",
        "  - Se o peso de uma entrada for alto, essa entrada ter√° mais influ√™ncia na sa√≠da do neur√¥nio. Um peso negativo pode inverter o efeito de uma entrada positiva.\n",
        "\n",
        "- **Bias (\\(b\\)):**\n",
        "  - O bias √© um termo adicional que permite ajustar o output do neur√¥nio independentemente das entradas. Ele ajuda o neur√¥nio a se deslocar da origem, o que √© crucial para a capacidade da rede de modelar corretamente os dados.\n",
        "  - Similar aos pesos, o bias tamb√©m √© um par√¢metro que √© ajustado durante o treinamento.\n",
        "\n",
        "### 1.3. Opera√ß√£o Interna do Neur√¥nio\n",
        "\n",
        "O neur√¥nio processa as entradas da seguinte maneira:\n",
        "\n",
        "#### 1.3.1. Soma Ponderada\n",
        "A primeira opera√ß√£o que o neur√¥nio realiza √© calcular a soma ponderada das entradas:\n",
        "\n",
        "\\[\n",
        "z = \\sum_{i=1}^{n} w_i \\cdot x_i + b = w_1x_1 + w_2x_2 + \\dots + w_nx_n + b\n",
        "\\]\n",
        "\n",
        "Aqui, \\(z\\) √© o resultado da soma ponderada, que √© uma combina√ß√£o linear das entradas.\n",
        "\n",
        "#### 1.3.2. Fun√ß√£o de Ativa√ß√£o\n",
        "Ap√≥s calcular a soma ponderada, o neur√¥nio passa esse valor atrav√©s de uma **fun√ß√£o de ativa√ß√£o** para introduzir n√£o-linearidade ao modelo. Sem essa n√£o-linearidade, a rede neural n√£o seria capaz de modelar problemas complexos.\n",
        "\n",
        "Algumas fun√ß√µes de ativa√ß√£o comuns incluem:\n",
        "\n",
        "- **ReLU (Rectified Linear Unit):**\n",
        "  \\[\n",
        "  a = \\text{ReLU}(z) = \\max(0, z)\n",
        "  \\]\n",
        "  - A ReLU ativa o neur√¥nio somente quando a soma ponderada √© positiva. √â muito usada por ser computacionalmente eficiente e ajudar a mitigar o problema do gradiente desaparecendo em redes profundas.\n",
        "\n",
        "- **Sigmoide:**\n",
        "  \\[\n",
        "  a = \\text{sigmoid}(z) = \\frac{1}{1 + e^{-z}}\n",
        "  \\]\n",
        "  - A fun√ß√£o sigmoide mapeia o valor \\(z\\) para um intervalo entre 0 e 1, sendo √∫til para modelos de classifica√ß√£o bin√°ria. No entanto, ela pode sofrer com o problema de gradientes pequenos em valores extremos.\n",
        "\n",
        "- **Tanh (Tangente Hiperb√≥lica):**\n",
        "  \\[\n",
        "  a = \\text{tanh}(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}\n",
        "  \\]\n",
        "  - Tanh √© similar √† fun√ß√£o sigmoide, mas mapeia o valor \\(z\\) para um intervalo entre -1 e 1, o que pode ser mais √∫til em algumas aplica√ß√µes.\n",
        "\n",
        "### 1.4. Sa√≠da do Neur√¥nio\n",
        "\n",
        "A sa√≠da do neur√¥nio \\(a\\) √© o valor produzido pela fun√ß√£o de ativa√ß√£o:\n",
        "\n",
        "\\[\n",
        "a = \\text{fun√ß√£o de ativa√ß√£o}(z)\n",
        "\\]\n",
        "\n",
        "Este valor \\(a\\) pode ser usado como a sa√≠da final do neur√¥nio ou servir como entrada para outros neur√¥nios em camadas subsequentes da rede neural.\n",
        "\n",
        "### 1.5. Interpreta√ß√£o e Treinamento\n",
        "\n",
        "No contexto do treinamento de redes neurais, o objetivo √© ajustar os pesos \\(w_i\\) e o bias \\(b\\) para que a sa√≠da do neur√¥nio esteja o mais pr√≥xima poss√≠vel do valor desejado (target). Isso √© feito usando algoritmos de otimiza√ß√£o, como o Gradient Descent, que minimizam uma fun√ß√£o de perda, representando o erro da rede.\n",
        "\n",
        "### 1.6. Import√¢ncia da Estrutura do Neur√¥nio\n",
        "\n",
        "A estrutura do neur√¥nio artificial, embora simples, permite que redes neurais modelam rela√ß√µes complexas entre entradas e sa√≠das. Ao empilhar muitos neur√¥nios e camadas, as redes podem capturar padr√µes e regularidades em dados complexos, como imagens, texto e s√©ries temporais.\n",
        "\n",
        "Essa compreens√£o detalhada da estrutura do neur√¥nio artificial √© essencial para entender como redes neurais mais complexas funcionam e como podemos trein√°-las para resolver problemas reais."
      ],
      "metadata": {
        "id": "yiW7VcZ-Nyz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos nos aprofundar na **estrutura de um neur√¥nio artificial**, um componente essencial das Redes Neurais Artificiais. Este conceito √© inspirado no neur√¥nio biol√≥gico, mas traduzido para o dom√≠nio matem√°tico e computacional.\n",
        "\n",
        "### Estrutura de um Neur√¥nio Artificial\n",
        "\n",
        "#### 1. **Entradas (Inputs) e Pesos (Weights)**\n",
        "\n",
        "Cada neur√¥nio artificial recebe m√∫ltiplas entradas, que podem ser denotadas como \\(x_1, x_2, \\dots, x_n\\). Essas entradas representam caracter√≠sticas ou dados que o modelo est√° processando. Para cada entrada, existe um peso associado (\\(w_1, w_2, \\dots, w_n\\)). Esses pesos s√£o valores num√©ricos que determinam a import√¢ncia de cada entrada.\n",
        "\n",
        "**Exemplo Pr√°tico:**\n",
        "Imagine que voc√™ est√° desenvolvendo um modelo de previs√£o de pre√ßos de casas, onde as entradas s√£o caracter√≠sticas como tamanho da casa, n√∫mero de quartos e localiza√ß√£o. O neur√¥nio receberia esses valores como entradas, e os pesos determinariam qu√£o importante cada uma dessas caracter√≠sticas √© para prever o pre√ßo.\n",
        "\n",
        "Matematicamente, a combina√ß√£o das entradas e pesos √© expressa como uma soma ponderada:\n",
        "\\[\n",
        "z = w_1x_1 + w_2x_2 + \\dots + w_nx_n + b\n",
        "\\]\n",
        "Aqui, \\(b\\) representa o **termo de bias** (vi√©s), que √© um valor adicional que permite que o neur√¥nio se ajuste de maneira mais flex√≠vel aos dados, movendo a fun√ß√£o de ativa√ß√£o para frente ou para tr√°s no eixo de decis√£o.\n",
        "\n",
        "#### 2. **Fun√ß√£o de Soma (Weighted Sum)**\n",
        "\n",
        "O valor \\(z\\) obtido √© a soma ponderada das entradas e pesos, incluindo o bias. Esta soma ponderada √© o que o neur√¥nio processa antes de tomar qualquer \"decis√£o\" sobre a sa√≠da.\n",
        "\n",
        "A fun√ß√£o de soma √© essencial porque integra todas as entradas de forma linear, combinando-as em um √∫nico valor que representa o estado atual das informa√ß√µes processadas pelo neur√¥nio. Este valor \\(z\\) ser√° ent√£o transformado por uma fun√ß√£o de ativa√ß√£o.\n",
        "\n",
        "#### 3. **Fun√ß√£o de Ativa√ß√£o (Activation Function)**\n",
        "\n",
        "Ap√≥s calcular a soma ponderada, o neur√¥nio passa este valor \\(z\\) por uma fun√ß√£o de ativa√ß√£o. A fun√ß√£o de ativa√ß√£o √© crucial porque ela introduz **n√£o-linearidade** ao sistema. Sem ela, a rede neural seria equivalente a uma simples regress√£o linear, incapaz de capturar rela√ß√µes complexas nos dados.\n",
        "\n",
        "As fun√ß√µes de ativa√ß√£o mais comuns incluem:\n",
        "\n",
        "- **ReLU (Rectified Linear Unit):** \\( \\text{ReLU}(z) = \\max(0, z) \\)  \n",
        "  A ReLU √© popular porque resolve o problema do desvanecimento do gradiente (gradient vanishing) em redes profundas e √© eficiente computacionalmente. Ela transforma valores negativos em zero e mant√©m os valores positivos inalterados.\n",
        "\n",
        "- **Sigmoide:** \\( \\sigma(z) = \\frac{1}{1 + e^{-z}} \\)  \n",
        "  A fun√ß√£o sigmoide √© usada principalmente em problemas de classifica√ß√£o bin√°ria. Ela mapeia a soma ponderada para um valor entre 0 e 1, interpret√°vel como uma probabilidade.\n",
        "\n",
        "- **Tanh (Tangente Hiperb√≥lica):** \\( \\text{Tanh}(z) = \\frac{2}{1 + e^{-2z}} - 1 \\)  \n",
        "  A tanh √© semelhante √† sigmoide, mas mapeia o valor de \\(z\\) para um intervalo entre -1 e 1. √â √∫til quando se quer centrar os dados em torno de zero.\n",
        "\n",
        "A sa√≠da do neur√¥nio ap√≥s a aplica√ß√£o da fun√ß√£o de ativa√ß√£o √©:\n",
        "\\[\n",
        "a = \\text{fun√ß√£o de ativa√ß√£o}(z)\n",
        "\\]\n",
        "onde \\(a\\) √© a sa√≠da do neur√¥nio, pronta para ser transmitida para a pr√≥xima camada na rede ou para gerar uma predi√ß√£o final, dependendo de onde o neur√¥nio se encontra na arquitetura da rede.\n",
        "\n",
        "#### 4. **Interpreta√ß√£o e Papel do Neur√¥nio Artificial**\n",
        "\n",
        "O neur√¥nio artificial, em ess√™ncia, toma uma decis√£o com base nas entradas que recebe e nos pesos associados a essas entradas. Ele processa as informa√ß√µes atrav√©s da fun√ß√£o de soma e decide, atrav√©s da fun√ß√£o de ativa√ß√£o, se deve \"ativar\" (ou seja, gerar uma sa√≠da significativa).\n",
        "\n",
        "Em uma rede neural, m√∫ltiplos neur√¥nios operam juntos, cada um processando suas respectivas entradas. O poder das redes neurais vem da capacidade de compor v√°rias camadas de neur√¥nios, cada uma capturando diferentes n√≠veis de abstra√ß√£o dos dados. Em camadas iniciais, os neur√¥nios podem identificar padr√µes simples (como bordas em uma imagem), enquanto camadas mais profundas identificam padr√µes complexos (como formas ou objetos inteiros).\n",
        "\n",
        "### Visualizando o Neur√¥nio Artificial\n",
        "\n",
        "Imagine o neur√¥nio como um filtro que recebe v√°rias informa√ß√µes, pesa cada uma, soma todas e decide, atrav√©s de uma fun√ß√£o matem√°tica, qual ser√° sua resposta. Se pensarmos em termos de uma rede neural complexa, cada neur√¥nio individualmente √© respons√°vel por uma pequena parte do trabalho, mas todos juntos formam um sistema poderoso capaz de aprender e fazer predi√ß√µes a partir dos dados.\n",
        "\n",
        "Essa estrutura b√°sica do neur√¥nio artificial √© o que permite que redes neurais, desde as mais simples at√© as mais profundas e complexas, sejam capazes de realizar tarefas como reconhecimento de imagem, tradu√ß√£o de linguagem e at√© mesmo conduzir carros autonomamente."
      ],
      "metadata": {
        "id": "plz-vCjPOsgD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## - Multilayer Perceptron (MLP)\"\n"
      ],
      "metadata": {
        "id": "6wHuAIdPmikD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Vamos aprofundar o conceito de **Multilayer Perceptron (MLP)**, uma das arquiteturas mais b√°sicas e fundamentais nas redes neurais artificiais. O MLP √© conhecido por ser uma rede neural totalmente conectada (fully connected) e √© frequentemente usado para problemas de classifica√ß√£o e regress√£o. Seu design permite que ele capture padr√µes complexos nos dados, gra√ßas √† sua arquitetura de m√∫ltiplas camadas.\n",
        "\n",
        "### Multilayer Perceptron (MLP)\n",
        "\n",
        "#### 1. **Estrutura do MLP**\n",
        "\n",
        "O MLP √© composto por v√°rias camadas de neur√¥nios artificiais, organizadas em:\n",
        "\n",
        "- **Camada de Entrada (Input Layer):** Esta camada recebe os dados diretamente. Cada neur√¥nio na camada de entrada corresponde a uma caracter√≠stica ou vari√°vel dos dados de entrada. Por exemplo, se estamos lidando com um conjunto de dados com tr√™s caracter√≠sticas (como altura, peso e idade), a camada de entrada ter√° tr√™s neur√¥nios.\n",
        "\n",
        "- **Camadas Ocultas (Hidden Layers):** As camadas intermedi√°rias entre a camada de entrada e a camada de sa√≠da. O termo \"oculta\" refere-se ao fato de que os valores dessas camadas n√£o s√£o vis√≠veis externamente; elas servem apenas para processar e transformar os dados. Um MLP pode ter uma ou v√°rias camadas ocultas, e a profundidade da rede depende do n√∫mero de camadas. Cada neur√¥nio em uma camada oculta realiza a opera√ß√£o de soma ponderada das sa√≠das da camada anterior, passa essa soma por uma fun√ß√£o de ativa√ß√£o e envia o resultado para a pr√≥xima camada.\n",
        "\n",
        "- **Camada de Sa√≠da (Output Layer):** A √∫ltima camada do MLP gera a predi√ß√£o final. O n√∫mero de neur√¥nios na camada de sa√≠da depende da tarefa. Para uma tarefa de classifica√ß√£o bin√°ria, h√° geralmente um neur√¥nio, enquanto que para classifica√ß√£o multiclasse, o n√∫mero de neur√¥nios corresponde ao n√∫mero de classes. Para regress√£o, a camada de sa√≠da geralmente tem um neur√¥nio.\n",
        "\n",
        "**Arquitetura T√≠pica:**\n",
        "- **N√∫mero de neur√¥nios na camada de entrada:** Depende das caracter√≠sticas do dataset (n√∫mero de vari√°veis de entrada).\n",
        "- **N√∫mero de camadas ocultas e neur√¥nios por camada:** Isso √© ajust√°vel, e √© uma parte cr√≠tica do design de redes neurais. Mais camadas e neur√¥nios permitem que a rede aprenda representa√ß√µes mais complexas, mas podem tamb√©m aumentar a chance de overfitting (sobreajuste).\n",
        "- **N√∫mero de neur√¥nios na camada de sa√≠da:** Depende da tarefa. Para problemas de classifica√ß√£o bin√°ria, h√° tipicamente um √∫nico neur√¥nio com uma fun√ß√£o de ativa√ß√£o sigmoide para gerar um valor entre 0 e 1, interpretado como probabilidade.\n",
        "\n",
        "#### 2. **Conex√µes entre as Camadas**\n",
        "\n",
        "Uma caracter√≠stica importante do MLP √© que ele √© uma rede neural **totalmente conectada**. Isso significa que:\n",
        "\n",
        "- Cada neur√¥nio em uma camada est√° conectado a todos os neur√¥nios da camada seguinte.\n",
        "- Cada conex√£o entre os neur√¥nios tem um peso associado, que ser√° ajustado durante o treinamento.\n",
        "\n",
        "Essa interconectividade garante que o MLP possa aprender padr√µes complexos nos dados, pois cada neur√¥nio recebe informa√ß√µes de todos os neur√¥nios da camada anterior. No entanto, isso tamb√©m significa que o n√∫mero de par√¢metros aumenta rapidamente com o aumento do n√∫mero de neur√¥nios e camadas.\n",
        "\n",
        "#### 3. **Processo de Treinamento no MLP**\n",
        "\n",
        "O processo de treinamento de um MLP envolve dois passos principais: **Forward Propagation** e **Backpropagation** (estes ser√£o detalhados em outras partes, mas aqui est√° uma vis√£o geral).\n",
        "\n",
        "- **Forward Propagation:** Durante a fase de forward propagation, as entradas s√£o passadas pela rede, camada por camada, at√© gerar uma predi√ß√£o. Em cada camada, a soma ponderada das entradas √© calculada, e o resultado √© passado por uma fun√ß√£o de ativa√ß√£o (como ReLU, sigmoide ou tanh).\n",
        "\n",
        "- **Backpropagation:** Ap√≥s o forward propagation, o erro entre a predi√ß√£o da rede e o valor real √© calculado usando uma fun√ß√£o de perda (loss function). Este erro √© propagado de volta atrav√©s da rede, e os pesos s√£o ajustados para minimizar o erro, usando um algoritmo de otimiza√ß√£o, como o gradient descent (descida do gradiente). Esse processo √© repetido v√°rias vezes (√©pocas) at√© que o modelo aprenda a fazer boas predi√ß√µes.\n",
        "\n",
        "#### 4. **Fun√ß√µes de Ativa√ß√£o nas Camadas Ocultas e de Sa√≠da**\n",
        "\n",
        "- **Fun√ß√µes de Ativa√ß√£o nas Camadas Ocultas:** O MLP usa fun√ß√µes de ativa√ß√£o n√£o lineares (como ReLU, sigmoide ou tanh) nas camadas ocultas para introduzir n√£o-linearidade. Isso permite que a rede aprenda rela√ß√µes complexas que n√£o podem ser modeladas por uma combina√ß√£o linear simples de pesos e entradas.\n",
        "\n",
        "- **Fun√ß√£o de Ativa√ß√£o na Camada de Sa√≠da:** A escolha da fun√ß√£o de ativa√ß√£o na camada de sa√≠da depende do tipo de problema:\n",
        "  - **Classifica√ß√£o Bin√°ria:** Usualmente, a fun√ß√£o sigmoide √© usada, pois ela mapeia o valor da sa√≠da para um intervalo entre 0 e 1, representando uma probabilidade.\n",
        "  - **Classifica√ß√£o Multiclasse:** Geralmente, a fun√ß√£o **softmax** √© usada, que mapeia a sa√≠da para uma distribui√ß√£o de probabilidade sobre m√∫ltiplas classes.\n",
        "  - **Regress√£o:** Para problemas de regress√£o, n√£o √© necess√°rio usar uma fun√ß√£o de ativa√ß√£o na camada de sa√≠da, pois o objetivo √© prever um valor cont√≠nuo.\n",
        "\n",
        "#### 5. **Capacidade de Aprendizado do MLP**\n",
        "\n",
        "O poder de um MLP est√° em sua capacidade de aprender representa√ß√µes a diferentes n√≠veis de abstra√ß√£o:\n",
        "\n",
        "- **Camadas Superficiais:** Capturam padr√µes mais simples e diretos dos dados. Por exemplo, em uma rede treinada para reconhecer d√≠gitos, as primeiras camadas podem identificar bordas e curvas.\n",
        "  \n",
        "- **Camadas Profundas:** Com m√∫ltiplas camadas ocultas, o MLP pode aprender a combinar esses padr√µes simples em padr√µes mais complexos. Em um exemplo de reconhecimento de imagem, as camadas mais profundas podem aprender a reconhecer formas inteiras, como n√∫meros ou letras.\n",
        "\n",
        "Embora o MLP tenha uma arquitetura poderosa, ele possui algumas limita√ß√µes:\n",
        "- **Escalabilidade:** Para problemas de alta dimens√£o (como imagens), o n√∫mero de par√¢metros cresce rapidamente, tornando o treinamento mais desafiador.\n",
        "- **Inabilidade de Capturar Padr√µes Sequenciais:** O MLP n√£o leva em considera√ß√£o a ordem sequencial dos dados, o que limita sua efic√°cia para problemas como modelagem de s√©ries temporais ou processamento de linguagem natural. Para esses problemas, arquiteturas como redes neurais recorrentes (RNNs) ou convolucionais (CNNs) s√£o mais apropriadas.\n",
        "\n",
        "#### 6. **Overfitting e Regulariza√ß√£o**\n",
        "\n",
        "Com grandes quantidades de neur√¥nios e camadas ocultas, um MLP pode facilmente \"memorizar\" os dados de treino, levando a um problema conhecido como **overfitting**, onde o modelo tem desempenho excelente nos dados de treinamento, mas falha em generalizar para novos dados.\n",
        "\n",
        "- **Regulariza√ß√£o:** Para combater o overfitting, t√©cnicas como **dropout** (desligar aleatoriamente alguns neur√¥nios durante o treinamento) e **penalidades de regulariza√ß√£o L2** (que restringem o crescimento dos pesos) s√£o frequentemente usadas. Essas t√©cnicas ajudam o MLP a se generalizar melhor para novos dados, reduzindo a chance de memorizar ru√≠dos espec√≠ficos dos dados de treinamento.\n",
        "\n",
        "### Conclus√£o\n",
        "\n",
        "O **Multilayer Perceptron** √© um modelo robusto e flex√≠vel, capaz de aprender padr√µes complexos nos dados, gra√ßas √† sua arquitetura de m√∫ltiplas camadas. Embora tenha limita√ß√µes para dados com alta dimensionalidade e dados sequenciais, o MLP continua sendo um ponto de partida essencial para o aprendizado profundo, especialmente em problemas de classifica√ß√£o e regress√£o."
      ],
      "metadata": {
        "id": "QJAo8zj7mYsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## - Foward e BackWard propagation"
      ],
      "metadata": {
        "id": "MH1si2sIO1l6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos nos aprofundar nos conceitos de **forward propagation** e **backpropagation**, que s√£o processos fundamentais para o treinamento de redes neurais, incluindo o **Multilayer Perceptron (MLP)**. Eles permitem que o modelo aprenda a partir dos dados ajustando os pesos de maneira eficiente, otimizando as predi√ß√µes realizadas pela rede neural.\n",
        "\n",
        "### Forward Propagation\n",
        "\n",
        "#### 1. **Defini√ß√£o e Funcionamento**\n",
        "O **forward propagation** √© o processo no qual os dados de entrada percorrem a rede neural, passando de uma camada para a outra, at√© chegar √† camada de sa√≠da. A rede realiza c√°lculos em cada neur√¥nio das camadas ocultas e na camada de sa√≠da, gerando uma predi√ß√£o final.\n",
        "\n",
        "Em termos simples, este processo envolve:\n",
        "\n",
        "1. Multiplicar os valores de entrada pelos pesos associados a cada conex√£o.\n",
        "2. Somar o resultado para obter a soma ponderada.\n",
        "3. Adicionar o bias (termo de vi√©s) √† soma ponderada.\n",
        "4. Passar a soma ponderada por uma fun√ß√£o de ativa√ß√£o, para introduzir n√£o-linearidade.\n",
        "5. Repetir este processo para cada camada at√© chegar √† camada de sa√≠da.\n",
        "\n",
        "##### Exemplo Pr√°tico:\n",
        "Considere um problema simples de classifica√ß√£o bin√°ria, onde queremos prever se uma pessoa tem ou n√£o uma determinada doen√ßa com base em tr√™s caracter√≠sticas: idade, peso e press√£o arterial. A entrada (\\( x_1, x_2, x_3 \\)) corresponde a essas tr√™s caracter√≠sticas, os pesos (\\( w_1, w_2, w_3 \\)) indicam a import√¢ncia de cada uma, e o processo de forward propagation vai calcular a predi√ß√£o da probabilidade de doen√ßa.\n",
        "\n",
        "1. Para cada neur√¥nio, a soma ponderada \\( z \\) √© calculada como:\n",
        "   \\[\n",
        "   z = w_1x_1 + w_2x_2 + w_3x_3 + b\n",
        "   \\]\n",
        "2. O valor \\( z \\) √© passado por uma fun√ß√£o de ativa√ß√£o (como ReLU ou sigmoide) para gerar a sa√≠da \\( a \\) do neur√¥nio:\n",
        "   \\[\n",
        "   a = \\sigma(z)\n",
        "   \\]\n",
        "3. Esse processo se repete para cada camada da rede at√© a camada de sa√≠da, onde o valor final √© a predi√ß√£o feita pela rede.\n",
        "\n",
        "#### 2. **Predi√ß√£o Final**\n",
        "Na camada de sa√≠da, a predi√ß√£o final √© gerada. Para problemas de classifica√ß√£o bin√°ria, essa predi√ß√£o pode ser um valor entre 0 e 1, interpretado como a probabilidade de um evento (por exemplo, se uma pessoa tem a doen√ßa). Para problemas de classifica√ß√£o multiclasse, a fun√ß√£o softmax pode ser usada para gerar probabilidades para cada classe.\n",
        "\n",
        "#### 3. **Limita√ß√µes do Forward Propagation**\n",
        "No forward propagation, n√£o h√° ajuste nos pesos da rede. Ele simplesmente calcula a sa√≠da baseada nos pesos atuais, que s√£o inicialmente aleat√≥rios. Portanto, o processo por si s√≥ n√£o faz a rede aprender; √© apenas uma fase de avalia√ß√£o. O aprendizado real ocorre durante o **backpropagation**, que ajusta os pesos para melhorar as predi√ß√µes futuras.\n",
        "\n",
        "---\n",
        "\n",
        "### Backpropagation\n",
        "\n",
        "#### 1. **Defini√ß√£o e Funcionamento**\n",
        "O **backpropagation** (retropropaga√ß√£o) √© o processo no qual o erro calculado na predi√ß√£o final √© propagado de volta atrav√©s da rede para ajustar os pesos. Isso permite que a rede melhore suas predi√ß√µes ao longo do tempo, reduzindo o erro.\n",
        "\n",
        "O objetivo do backpropagation √© minimizar uma fun√ß√£o de perda, como o erro quadr√°tico m√©dio (MSE) ou a entropia cruzada, dependendo do tipo de problema (regress√£o ou classifica√ß√£o).\n",
        "\n",
        "#### 2. **Etapas do Backpropagation**\n",
        "\n",
        "O processo de backpropagation envolve as seguintes etapas:\n",
        "\n",
        "##### 1. **C√°lculo do Erro na Camada de Sa√≠da**\n",
        "Depois que o forward propagation √© completado, a predi√ß√£o gerada pela rede \\( \\hat{y} \\) √© comparada com o valor real \\( y \\). A diferen√ßa entre \\( \\hat{y} \\) e \\( y \\) √© o **erro** da rede.\n",
        "\n",
        "Para um problema de regress√£o, podemos usar uma fun√ß√£o de perda como o erro quadr√°tico m√©dio:\n",
        "\\[\n",
        "\\text{Loss} = \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2\n",
        "\\]\n",
        "\n",
        "##### 2. **C√°lculo do Gradiente**\n",
        "O erro calculado √© usado para determinar o quanto cada peso na rede contribuiu para esse erro. Isso √© feito calculando o **gradiente** da fun√ß√£o de perda em rela√ß√£o aos pesos, usando a **regra da cadeia**.\n",
        "\n",
        "A regra da cadeia √© uma t√©cnica de c√°lculo que permite calcular a derivada de uma fun√ß√£o composta. Como os valores de sa√≠da dependem dos pesos e dos valores de ativa√ß√£o, que por sua vez dependem dos pesos da camada anterior, precisamos calcular essas derivadas de forma sequencial.\n",
        "\n",
        "O gradiente √© a inclina√ß√£o da fun√ß√£o de perda em rela√ß√£o a um determinado peso, ou seja, ele indica o quanto a fun√ß√£o de perda mudar√° se ajustarmos ligeiramente esse peso. O objetivo √© ajustar os pesos na dire√ß√£o que minimize a perda.\n",
        "\n",
        "##### 3. **Ajuste dos Pesos**\n",
        "Os pesos s√£o atualizados com base nos gradientes calculados. Isso √© feito usando um algoritmo de otimiza√ß√£o como a **descida do gradiente** (gradient descent). O peso \\( w \\) √© atualizado pela regra:\n",
        "\\[\n",
        "w_{novo} = w_{atual} - \\eta \\cdot \\frac{\\partial \\text{Loss}}{\\partial w}\n",
        "\\]\n",
        "onde \\( \\eta \\) √© a **taxa de aprendizado** (learning rate) e \\( \\frac{\\partial \\text{Loss}}{\\partial w} \\) √© o gradiente da fun√ß√£o de perda em rela√ß√£o ao peso \\( w \\).\n",
        "\n",
        "Esse processo √© repetido para cada peso na rede, ajustando-os na dire√ß√£o que reduz o erro da predi√ß√£o.\n",
        "\n",
        "##### 4. **Propaga√ß√£o do Erro para Camadas Anteriores**\n",
        "O erro da camada de sa√≠da √© propagado para as camadas ocultas. O erro em uma camada oculta √© calculado com base nos erros das camadas subsequentes. Isso permite que o modelo ajuste os pesos em todas as camadas, n√£o apenas na camada de sa√≠da.\n",
        "\n",
        "#### 3. **Algoritmo de Descida do Gradiente**\n",
        "O algoritmo de descida do gradiente √© um dos m√©todos mais comuns para ajustar os pesos. Ele trabalha iterativamente para reduzir o erro ajustando os pesos em pequenas quantidades. Dependendo da abordagem, existem algumas varia√ß√µes da descida do gradiente:\n",
        "- **Batch Gradient Descent:** Calcula o gradiente em todo o conjunto de dados de treinamento antes de atualizar os pesos.\n",
        "- **Stochastic Gradient Descent (SGD):** Atualiza os pesos ap√≥s cada exemplo de treino, o que torna o processo mais r√°pido, mas com mais varia√ß√£o.\n",
        "- **Mini-batch Gradient Descent:** Uma combina√ß√£o das duas anteriores, atualizando os pesos ap√≥s processar pequenos lotes de exemplos.\n",
        "\n",
        "Al√©m disso, pode-se usar variantes como **Adam**, **RMSProp**, e **Momentum**, que adaptam dinamicamente a taxa de aprendizado ou aceleram a converg√™ncia.\n",
        "\n",
        "---\n",
        "\n",
        "### Rela√ß√£o entre Forward Propagation e Backpropagation\n",
        "\n",
        "O forward propagation e o backpropagation trabalham juntos no treinamento de redes neurais:\n",
        "\n",
        "1. **Forward Propagation:** Transforma os dados de entrada em uma predi√ß√£o. Durante essa fase, as ativa√ß√µes de cada camada s√£o armazenadas, para que possam ser usadas no c√°lculo do gradiente na fase de backpropagation.\n",
        "  \n",
        "2. **Backpropagation:** Com base na predi√ß√£o gerada e no erro calculado, os pesos s√£o ajustados para reduzir o erro em futuras predi√ß√µes.\n",
        "\n",
        "Este processo de forward e backward √© repetido por muitas itera√ß√µes (√©pocas), at√© que a rede neural converja para uma solu√ß√£o que minimize a fun√ß√£o de perda e maximize o desempenho nas predi√ß√µes.\n",
        "\n",
        "### Conclus√£o\n",
        "\n",
        "**Forward propagation** √© o processo de calcular a sa√≠da de uma rede neural a partir das entradas, enquanto **backpropagation** ajusta os pesos da rede para reduzir o erro nas predi√ß√µes futuras. A combina√ß√£o desses dois processos √© o cora√ß√£o do treinamento de redes neurais, permitindo que modelos aprendam com dados e melhorem seu desempenho ao longo do tempo."
      ],
      "metadata": {
        "id": "DG83XDIQmUo0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10/09\n"
      ],
      "metadata": {
        "id": "3xUl-vpmaGPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mWMP5p2QaIDh"
      }
    }
  ]
}