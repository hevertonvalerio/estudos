{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMu+JeH5NZyNQEhyG4PGui5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hevertonvalerio/estudos/blob/main/Anota%C3%A7%C3%B5es_GE_Deep_Learning_e_Intro_a_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seperação dos grupos"
      ],
      "metadata": {
        "id": "nNfFtAZHtTeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Participação ativa - Pesquisa com materiais para próxima sessão.\n",
        "\n",
        "Roteiro para o econtro. Propor a condução de cada encontro.\n",
        "\n",
        "Exemplos de códigos\n",
        "\n",
        "Alguns alunos propõe e os outros fazem pergunta."
      ],
      "metadata": {
        "id": "Id_975m_tfH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Grupo de Introdução à IA"
      ],
      "metadata": {
        "id": "THMF_Z2HwkiG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. referencias de trabalho e contexto, ferram.\n",
        "\n",
        "2. eda - Como eles são limpos para uma analise adequada?\n",
        "\n",
        "3. Matematica\n",
        "\n",
        "4. Se funciona ou não\n",
        "\n",
        "5. Algoritimo mais simples\n",
        "\n",
        "6.\n"
      ],
      "metadata": {
        "id": "mhHBK7NbuHWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Curso AWS - Machine Learning - ML foundation**\n",
        "\n",
        "Ainda não está disponível - Prof Gustavo Scalabrini"
      ],
      "metadata": {
        "id": "-EKVY3uPwav4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cronograma grupo de Estudos Depp Learning"
      ],
      "metadata": {
        "id": "VCktQ1vfzf6H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Biblioteca > Livros eletronicos > \"Minha Biblioteca - biblioteca digital\""
      ],
      "metadata": {
        "id": "jf6evVFhzjLR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apresentação Segunda Semana (17/09)\n",
        "\n"
      ],
      "metadata": {
        "id": "Cxg37dh1__i2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## - Estrutura de um neurônio artificial\n"
      ],
      "metadata": {
        "id": "YUqzwlkOOxRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos nos aprofundar na estrutura de um neurônio artificial, que é a base das Redes Neurais Artificiais. Este conceito é fundamental para entender como as redes neurais processam informações e realizam tarefas como classificação, regressão, e reconhecimento de padrões.\n",
        "\n",
        "1. Introdução ao Neurônio Artificial\n",
        "Um neurônio artificial é uma abstração matemática inspirada no neurônio biológico, mas adaptada para processamento computacional. Ele é a menor unidade de uma rede neural e tem a capacidade de aprender padrões a partir de dados, ajustando seus parâmetros internos (pesos e bias) durante o treinamento.\n",
        "\n",
        "2. Componentes de um Neurônio Artificial\n",
        "2.1. Entradas (Inputs)\n",
        "As entradas para um neurônio artificial são valores numéricos que representam características ou atributos dos dados. Por exemplo, em um problema de reconhecimento de dígitos manuscritos, cada pixel de uma imagem pode ser uma entrada. Essas entradas são representadas como um vetor\n",
        "𝑥\n",
        "=\n",
        "[\n",
        "𝑥\n",
        "1\n",
        ",\n",
        "𝑥\n",
        "2\n",
        ",\n",
        "…\n",
        ",\n",
        "𝑥\n",
        "𝑛\n",
        "]\n",
        "x=[x\n",
        "1\n",
        "​\n",
        " ,x\n",
        "2\n",
        "​\n",
        " ,…,x\n",
        "n\n",
        "​\n",
        " ], onde cada\n",
        "𝑥\n",
        "𝑖\n",
        "x\n",
        "i\n",
        "​\n",
        "  é uma característica específica.\n",
        "\n",
        "2.2. Pesos (Weights)\n",
        "Cada entrada\n",
        "𝑥\n",
        "𝑖\n",
        "x\n",
        "i\n",
        "​\n",
        "  é associada a um peso\n",
        "𝑤\n",
        "𝑖\n",
        "w\n",
        "i\n",
        "​\n",
        " , que indica a importância relativa daquela entrada no processo de decisão do neurônio. Os pesos são parâmetros aprendidos durante o treinamento e são ajustados para minimizar o erro da rede. A ideia é que entradas mais relevantes para a tarefa tenham pesos maiores, enquanto entradas menos relevantes tenham pesos menores.\n",
        "\n",
        "Matematicamente, os pesos podem ser representados como um vetor\n",
        "𝑤\n",
        "=\n",
        "[\n",
        "𝑤\n",
        "1\n",
        ",\n",
        "𝑤\n",
        "2\n",
        ",\n",
        "…\n",
        ",\n",
        "𝑤\n",
        "𝑛\n",
        "]\n",
        "w=[w\n",
        "1\n",
        "​\n",
        " ,w\n",
        "2\n",
        "​\n",
        " ,…,w\n",
        "n\n",
        "​\n",
        " ].\n",
        "\n",
        "2.3. Soma Ponderada (Weighted Sum)\n",
        "O neurônio calcula a soma ponderada das entradas, que é essencialmente uma combinação linear das entradas e seus pesos. Essa operação é crucial porque combina as informações das entradas em um único valor, que será processado pela função de ativação.\n",
        "\n",
        "A soma ponderada é dada por:\n",
        "\n",
        "𝑧\n",
        "=\n",
        "∑\n",
        "𝑖\n",
        "=\n",
        "1\n",
        "𝑛\n",
        "𝑤\n",
        "𝑖\n",
        "⋅\n",
        "𝑥\n",
        "𝑖\n",
        "+\n",
        "𝑏\n",
        "z=\n",
        "i=1\n",
        "∑\n",
        "n\n",
        "​\n",
        " w\n",
        "i\n",
        "​\n",
        " ⋅x\n",
        "i\n",
        "​\n",
        " +b\n",
        "Aqui,\n",
        "𝑏\n",
        "b é o bias (viés), um termo adicional que permite ao neurônio ajustar a soma ponderada de maneira a não depender exclusivamente das entradas. O bias ajuda o modelo a se deslocar pela função de ativação, permitindo que a rede modele padrões mais complexos.\n",
        "\n",
        "2.4. Função de Ativação\n",
        "Depois de calcular a soma ponderada, o neurônio passa esse valor através de uma função de ativação. A função de"
      ],
      "metadata": {
        "id": "eL06cjr0NeKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos aprofundar nossa compreensão sobre a **estrutura de um neurônio artificial**, que é a unidade fundamental de uma rede neural artificial.\n",
        "\n",
        "### 1.1. Neurônio Artificial: Visão Geral\n",
        "\n",
        "Um neurônio artificial é modelado para simular o comportamento de um neurônio biológico. Ele recebe múltiplos sinais de entrada, processa esses sinais e gera uma saída. Esta saída pode servir como entrada para outros neurônios na rede, formando um sistema interconectado.\n",
        "\n",
        "### 1.2. Componentes do Neurônio Artificial\n",
        "\n",
        "Cada neurônio artificial é composto por três elementos principais:\n",
        "\n",
        "- **Entradas (\\(x_1, x_2, \\dots, x_n\\)):**\n",
        "  - Essas são as características ou dados que o neurônio processa. Cada entrada \\(x_i\\) representa uma característica do dado de entrada.\n",
        "  - Essas entradas são frequentemente valores numéricos, como pixels de uma imagem, medições de sensores, ou características extraídas de textos.\n",
        "\n",
        "- **Pesos (\\(w_1, w_2, \\dots, w_n\\)):**\n",
        "  - Cada entrada é associada a um peso \\(w_i\\), que determina a importância relativa dessa entrada no cálculo final.\n",
        "  - Pesos são parâmetros aprendíveis da rede, ajustados durante o processo de treinamento. Inicialmente, eles podem ser atribuídos aleatoriamente ou com base em algum critério específico.\n",
        "  - Se o peso de uma entrada for alto, essa entrada terá mais influência na saída do neurônio. Um peso negativo pode inverter o efeito de uma entrada positiva.\n",
        "\n",
        "- **Bias (\\(b\\)):**\n",
        "  - O bias é um termo adicional que permite ajustar o output do neurônio independentemente das entradas. Ele ajuda o neurônio a se deslocar da origem, o que é crucial para a capacidade da rede de modelar corretamente os dados.\n",
        "  - Similar aos pesos, o bias também é um parâmetro que é ajustado durante o treinamento.\n",
        "\n",
        "### 1.3. Operação Interna do Neurônio\n",
        "\n",
        "O neurônio processa as entradas da seguinte maneira:\n",
        "\n",
        "#### 1.3.1. Soma Ponderada\n",
        "A primeira operação que o neurônio realiza é calcular a soma ponderada das entradas:\n",
        "\n",
        "\\[\n",
        "z = \\sum_{i=1}^{n} w_i \\cdot x_i + b = w_1x_1 + w_2x_2 + \\dots + w_nx_n + b\n",
        "\\]\n",
        "\n",
        "Aqui, \\(z\\) é o resultado da soma ponderada, que é uma combinação linear das entradas.\n",
        "\n",
        "#### 1.3.2. Função de Ativação\n",
        "Após calcular a soma ponderada, o neurônio passa esse valor através de uma **função de ativação** para introduzir não-linearidade ao modelo. Sem essa não-linearidade, a rede neural não seria capaz de modelar problemas complexos.\n",
        "\n",
        "Algumas funções de ativação comuns incluem:\n",
        "\n",
        "- **ReLU (Rectified Linear Unit):**\n",
        "  \\[\n",
        "  a = \\text{ReLU}(z) = \\max(0, z)\n",
        "  \\]\n",
        "  - A ReLU ativa o neurônio somente quando a soma ponderada é positiva. É muito usada por ser computacionalmente eficiente e ajudar a mitigar o problema do gradiente desaparecendo em redes profundas.\n",
        "\n",
        "- **Sigmoide:**\n",
        "  \\[\n",
        "  a = \\text{sigmoid}(z) = \\frac{1}{1 + e^{-z}}\n",
        "  \\]\n",
        "  - A função sigmoide mapeia o valor \\(z\\) para um intervalo entre 0 e 1, sendo útil para modelos de classificação binária. No entanto, ela pode sofrer com o problema de gradientes pequenos em valores extremos.\n",
        "\n",
        "- **Tanh (Tangente Hiperbólica):**\n",
        "  \\[\n",
        "  a = \\text{tanh}(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}\n",
        "  \\]\n",
        "  - Tanh é similar à função sigmoide, mas mapeia o valor \\(z\\) para um intervalo entre -1 e 1, o que pode ser mais útil em algumas aplicações.\n",
        "\n",
        "### 1.4. Saída do Neurônio\n",
        "\n",
        "A saída do neurônio \\(a\\) é o valor produzido pela função de ativação:\n",
        "\n",
        "\\[\n",
        "a = \\text{função de ativação}(z)\n",
        "\\]\n",
        "\n",
        "Este valor \\(a\\) pode ser usado como a saída final do neurônio ou servir como entrada para outros neurônios em camadas subsequentes da rede neural.\n",
        "\n",
        "### 1.5. Interpretação e Treinamento\n",
        "\n",
        "No contexto do treinamento de redes neurais, o objetivo é ajustar os pesos \\(w_i\\) e o bias \\(b\\) para que a saída do neurônio esteja o mais próxima possível do valor desejado (target). Isso é feito usando algoritmos de otimização, como o Gradient Descent, que minimizam uma função de perda, representando o erro da rede.\n",
        "\n",
        "### 1.6. Importância da Estrutura do Neurônio\n",
        "\n",
        "A estrutura do neurônio artificial, embora simples, permite que redes neurais modelam relações complexas entre entradas e saídas. Ao empilhar muitos neurônios e camadas, as redes podem capturar padrões e regularidades em dados complexos, como imagens, texto e séries temporais.\n",
        "\n",
        "Essa compreensão detalhada da estrutura do neurônio artificial é essencial para entender como redes neurais mais complexas funcionam e como podemos treiná-las para resolver problemas reais."
      ],
      "metadata": {
        "id": "yiW7VcZ-Nyz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos nos aprofundar na **estrutura de um neurônio artificial**, um componente essencial das Redes Neurais Artificiais. Este conceito é inspirado no neurônio biológico, mas traduzido para o domínio matemático e computacional.\n",
        "\n",
        "### Estrutura de um Neurônio Artificial\n",
        "\n",
        "#### 1. **Entradas (Inputs) e Pesos (Weights)**\n",
        "\n",
        "Cada neurônio artificial recebe múltiplas entradas, que podem ser denotadas como \\(x_1, x_2, \\dots, x_n\\). Essas entradas representam características ou dados que o modelo está processando. Para cada entrada, existe um peso associado (\\(w_1, w_2, \\dots, w_n\\)). Esses pesos são valores numéricos que determinam a importância de cada entrada.\n",
        "\n",
        "**Exemplo Prático:**\n",
        "Imagine que você está desenvolvendo um modelo de previsão de preços de casas, onde as entradas são características como tamanho da casa, número de quartos e localização. O neurônio receberia esses valores como entradas, e os pesos determinariam quão importante cada uma dessas características é para prever o preço.\n",
        "\n",
        "Matematicamente, a combinação das entradas e pesos é expressa como uma soma ponderada:\n",
        "\\[\n",
        "z = w_1x_1 + w_2x_2 + \\dots + w_nx_n + b\n",
        "\\]\n",
        "Aqui, \\(b\\) representa o **termo de bias** (viés), que é um valor adicional que permite que o neurônio se ajuste de maneira mais flexível aos dados, movendo a função de ativação para frente ou para trás no eixo de decisão.\n",
        "\n",
        "#### 2. **Função de Soma (Weighted Sum)**\n",
        "\n",
        "O valor \\(z\\) obtido é a soma ponderada das entradas e pesos, incluindo o bias. Esta soma ponderada é o que o neurônio processa antes de tomar qualquer \"decisão\" sobre a saída.\n",
        "\n",
        "A função de soma é essencial porque integra todas as entradas de forma linear, combinando-as em um único valor que representa o estado atual das informações processadas pelo neurônio. Este valor \\(z\\) será então transformado por uma função de ativação.\n",
        "\n",
        "#### 3. **Função de Ativação (Activation Function)**\n",
        "\n",
        "Após calcular a soma ponderada, o neurônio passa este valor \\(z\\) por uma função de ativação. A função de ativação é crucial porque ela introduz **não-linearidade** ao sistema. Sem ela, a rede neural seria equivalente a uma simples regressão linear, incapaz de capturar relações complexas nos dados.\n",
        "\n",
        "As funções de ativação mais comuns incluem:\n",
        "\n",
        "- **ReLU (Rectified Linear Unit):** \\( \\text{ReLU}(z) = \\max(0, z) \\)  \n",
        "  A ReLU é popular porque resolve o problema do desvanecimento do gradiente (gradient vanishing) em redes profundas e é eficiente computacionalmente. Ela transforma valores negativos em zero e mantém os valores positivos inalterados.\n",
        "\n",
        "- **Sigmoide:** \\( \\sigma(z) = \\frac{1}{1 + e^{-z}} \\)  \n",
        "  A função sigmoide é usada principalmente em problemas de classificação binária. Ela mapeia a soma ponderada para um valor entre 0 e 1, interpretável como uma probabilidade.\n",
        "\n",
        "- **Tanh (Tangente Hiperbólica):** \\( \\text{Tanh}(z) = \\frac{2}{1 + e^{-2z}} - 1 \\)  \n",
        "  A tanh é semelhante à sigmoide, mas mapeia o valor de \\(z\\) para um intervalo entre -1 e 1. É útil quando se quer centrar os dados em torno de zero.\n",
        "\n",
        "A saída do neurônio após a aplicação da função de ativação é:\n",
        "\\[\n",
        "a = \\text{função de ativação}(z)\n",
        "\\]\n",
        "onde \\(a\\) é a saída do neurônio, pronta para ser transmitida para a próxima camada na rede ou para gerar uma predição final, dependendo de onde o neurônio se encontra na arquitetura da rede.\n",
        "\n",
        "#### 4. **Interpretação e Papel do Neurônio Artificial**\n",
        "\n",
        "O neurônio artificial, em essência, toma uma decisão com base nas entradas que recebe e nos pesos associados a essas entradas. Ele processa as informações através da função de soma e decide, através da função de ativação, se deve \"ativar\" (ou seja, gerar uma saída significativa).\n",
        "\n",
        "Em uma rede neural, múltiplos neurônios operam juntos, cada um processando suas respectivas entradas. O poder das redes neurais vem da capacidade de compor várias camadas de neurônios, cada uma capturando diferentes níveis de abstração dos dados. Em camadas iniciais, os neurônios podem identificar padrões simples (como bordas em uma imagem), enquanto camadas mais profundas identificam padrões complexos (como formas ou objetos inteiros).\n",
        "\n",
        "### Visualizando o Neurônio Artificial\n",
        "\n",
        "Imagine o neurônio como um filtro que recebe várias informações, pesa cada uma, soma todas e decide, através de uma função matemática, qual será sua resposta. Se pensarmos em termos de uma rede neural complexa, cada neurônio individualmente é responsável por uma pequena parte do trabalho, mas todos juntos formam um sistema poderoso capaz de aprender e fazer predições a partir dos dados.\n",
        "\n",
        "Essa estrutura básica do neurônio artificial é o que permite que redes neurais, desde as mais simples até as mais profundas e complexas, sejam capazes de realizar tarefas como reconhecimento de imagem, tradução de linguagem e até mesmo conduzir carros autonomamente."
      ],
      "metadata": {
        "id": "plz-vCjPOsgD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "MH1si2sIO1l6"
      }
    }
  ]
}